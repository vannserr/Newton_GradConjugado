{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIZj78yU_afP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize, newton"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_1b2YDL6nwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def funcao_objetivo(xk):\n",
        "\n",
        "    #f = 2*xk[0]**2 + 3*xk[1]**2 + xk[2]**2 + (1/2)*(2*xk[0] + xk[1]**2 + xk[2] - 5)**2 + (1/2)*(5*xk[0]**2 - xk[1]**2 - xk[2] - 2)**2\n",
        "\n",
        "    f = (xk[0]**4 - 16*xk[0]**2 + 5*xk[0]) + (xk[1]**4 - 16*xk[1]**2 + 5*xk[1]) + (xk[2]**4 - 16*xk[2]**2 + 5*xk[2]) + (xk[3]**4 - 16*xk[3]**2 + 5*xk[3])\n",
        "    #(w^4 - 16*w^2 + 5*w) + (x^4 - 16*x^2 + 5*x) + (y^4 - 16*y^2 + 5*y) + (z^4 - 16*z^2 + 5*z)\n",
        "\n",
        "    return f"
      ],
      "metadata": {
        "id": "0Muxs2Dd_rCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradiente(xk):\n",
        " \n",
        "    gk = np.array( [ (4*xk[0]**3 - 32*xk[0]+ 5),\n",
        "                    (4*xk[1]**3 - 32*xk[1] + 5),\n",
        "                    (4*xk[2]**3 - 32*xk[2] + 5),\n",
        "                    4*xk[3]**3 - 32*xk[3] + 5   ] )\n",
        "         \n",
        "\n",
        "#4x^3 – 32 x^2+5\n",
        "\n",
        "    #gk = np.array( [2*(-5 + 25*xk[0]**3 + xk[1]**2 + xk[2] - xk[0]*(6 + 5*xk[1]**2 + 5*xk[2])),\n",
        "     #               2*xk[1]*(2*xk[0] - 5*xk[0]**2 + 2*(xk[1]**2 + xk[2])),\n",
        "      #              -3 + 2*xk[0] - 5*xk[0]**2 + 2*xk[1]**2 + 4*xk[2]   ] )\n",
        "    return gk"
      ],
      "metadata": {
        "id": "Xzj0GSEQ7aBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hessiana(xk):\n",
        "\n",
        "  h = np.array([\n",
        "        [ 12*xk[0]**2 - 64,  0,   0,   0  ],   \n",
        "        [   0   ,  12*xk[1]**2,   0 ,  0  ],\n",
        "        [   0   ,  0  ,  12*xk[2]**2 , 0  ],\n",
        "        [   0   ,  0  ,  0 ,  12*xk[3]**2 ]])\n",
        "  \n",
        "\n",
        "\n",
        "#12x^2 – 64\n",
        "\n",
        "  #h = np.array([\n",
        "   #     [-639 + 60000*xk[0]**2 - 400*xk[1]**2 - 400*xk[2],   160*(1 - 5*xk[0])*xk[1]  , 80 - 400*xk[0] ],   #Hessiana com rho = 40\n",
        "    #    [ 160*(1 - 5*xk[0])*xk[1],  2*(-117 + 80*xk[0] - 200*xk[0]**2 + 240*xk[1]**2 + 80*xk[2] ), 160*xk[1] ],\n",
        "     #   [80 - 400*xk[0] , 1600*xk[1], 82 ]\n",
        "   # ])\n",
        "\n",
        "  return h"
      ],
      "metadata": {
        "id": "jnz0Cngd7IdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#x0 = np.array([-3,-3,-3,-3])\n",
        "#xopt = newton(funcao_objetivo, x0, fprime=gradiente, tol=1e-4, maxiter =100,  fprime2=hessiana)\n",
        "\n",
        "\n",
        "\n",
        "#cipy.optimize.newton(func, x0, fprime=None, args=(),\n",
        " #                    tol=1.48e-08, maxiter=50, fprime2=None, x1=None, rtol=0.0, full_output=False, disp=True"
      ],
      "metadata": {
        "id": "TXwvbv3C68p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfNYindn6uvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def armijo(xk, sk):\n",
        " \n",
        "    alpha = 1 #Cambio 2, despues de alterar el x0 mexer en alfa\n",
        "    a = 0.0\n",
        "    b = -sys.maxsize\n",
        "    c_1 = 0.0001\n",
        "    c_2 = 0.9\n",
        "    k = 0\n",
        "    while k < 100: #cambio 4 de 100 para 10\n",
        "        k += 1\n",
        "        #xk = np.ones((3,3), dtype=float)#TypeError: Cannot cast ufunc add output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n",
        "        if funcao_objetivo(xk) - funcao_objetivo(xk + alpha * sk) >= -c_1 * alpha * np.dot(gradiente(xk), sk):\n",
        "         \n",
        "            if np.dot(gradiente(xk + alpha * sk), sk) >= c_2 * np.dot(gradiente(xk), sk):\n",
        "             \n",
        "                return alpha\n",
        "            else:\n",
        "                a = alpha\n",
        "                alpha = min(2 * alpha, (alpha + b) / 2)\n",
        " \n",
        "        else:\n",
        "            b = alpha\n",
        "            alpha = 0.5 * (alpha + a)\n",
        "    return alpha"
      ],
      "metadata": {
        "id": "fiJy-aIzAK30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "if __name__ == '__main__':\n",
        "    eps = 1e-5\n",
        "    x0 = np.array([5,5,5,5])#([1,1,1,1])#([-1,-1,-1,-1])#([-2.5,-2.5,-2.5,-2.5])\n",
        " \n",
        "         # Algoritmo de gradiente \n",
        "    \n",
        "    gk = gradiente(x0)\n",
        "    sigma = np.linalg.norm(gk)\n",
        "    step = 0\n",
        "    xk = x0\n",
        "    w = np.zeros ((4, 50)) # Guarde la iteración y establezca la variable xk\n",
        "    sk = -1 * gk\n",
        "    while sigma > eps and step < 50: # Cambio 4 a 20 iter\n",
        "        alpha = armijo(xk, sk)\n",
        "        w[:, step] = np.transpose(xk)\n",
        " \n",
        "        step += 1\n",
        "        #xk = np.ones((3,3), dtype=float)#TypeError: Cannot cast ufunc add output from dtype('float64') to dtype('int64') with casting rule 'same_kind'\n",
        "        #xk += alpha * sk\n",
        "        xk = xk + alpha * sk\n",
        " \n",
        "        gk = gradiente(xk)\n",
        "        sk = -1 * gk\n",
        " \n",
        "        sigma = np.linalg.norm(gk)\n",
        "        #print(gk,sigma)\n",
        "        print('--A {}-ésima iter, resultado é {}, o alfa é {}, função objetivo {:.4f}'.format(step, np.array(xk), alpha, funcao_objetivo(xk)))\n",
        "        \n",
        "        #plt.plot (step, object_function(xk))\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-5Ck7HKTiBa",
        "outputId": "71fd6927-be4e-4b07-92ab-892c8f16ba8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--A 1-ésima iter, resultado é [-0.390625 -0.390625 -0.390625 -0.390625], o alfa é 0.015625, função objetivo -17.4850\n",
            "--A 2-ésima iter, resultado é [-3.62717152 -3.62717152 -3.62717152 -3.62717152], o alfa é 0.1875, função objetivo -222.1907\n",
            "--A 3-ésima iter, resultado é [-2.53635589 -2.53635589 -2.53635589 -2.53635589], o alfa é 0.015625, função objetivo -296.9064\n",
            "--A 4-ésima iter, resultado é [-3.18938252 -3.18938252 -3.18938252 -3.18938252], o alfa é 0.03125, função objetivo -300.9145\n",
            "--A 5-ésima iter, resultado é [-2.83451678 -2.83451678 -2.83451678 -2.83451678], o alfa é 0.015625, função objetivo -312.6856\n",
            "--A 6-ésima iter, resultado é [-2.90653244 -2.90653244 -2.90653244 -2.90653244], o alfa é 0.015625, função objetivo -313.3281\n",
            "--A 7-ésima iter, resultado é [-2.9032871 -2.9032871 -2.9032871 -2.9032871], o alfa é 0.015625, função objetivo -313.3293\n",
            "--A 8-ésima iter, resultado é [-2.90355393 -2.90355393 -2.90355393 -2.90355393], o alfa é 0.015625, função objetivo -313.3293\n",
            "--A 9-ésima iter, resultado é [-2.90353242 -2.90353242 -2.90353242 -2.90353242], o alfa é 0.015625, função objetivo -313.3293\n",
            "--A 10-ésima iter, resultado é [-2.90353416 -2.90353416 -2.90353416 -2.90353416], o alfa é 0.015625, função objetivo -313.3293\n",
            "--A 11-ésima iter, resultado é [-2.90353402 -2.90353402 -2.90353402 -2.90353402], o alfa é 0.015625, função objetivo -313.3293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "if __name__ == '__main__':\n",
        "    eps = 1e-5\n",
        "    x0 = np.array([0,0,0,0])#([1,1,1,1])#([5,5,5,5])#([-2,-2,-2,-2])##([-1,-1,-1,-1])#\n",
        " \n",
        "         # Algoritmo de gradiente conjugado\n",
        "    \n",
        "    xk = x0\n",
        "    gk = gradiente(xk)\n",
        "    sigma = np.linalg.norm(gk)\n",
        "    sk = -gk\n",
        "    step = 0\n",
        "    w = np.zeros ((4,1000)) # Guarde la iteración y establezca la variable xk\n",
        " \n",
        "    while sigma > eps and step < 1000:\n",
        "        w[:, step] = np.transpose(xk)\n",
        " \n",
        "        step += 1\n",
        "        alpha = armijo(xk, sk)\n",
        "        xk = xk + alpha * sk\n",
        "        g0 = gk\n",
        "        gk = gradiente(xk)\n",
        "        beta = (np.linalg.norm(gk) / np.linalg.norm(g0))**2\n",
        "        sk = -1 * gk + beta * sk\n",
        "        sigma = np.linalg.norm(gk)\n",
        "        print('--A {}-ésima iter, resultado é {}, alfa é {}, função objetivo {:.4f}'.format(step, np.array(xk), alpha, funcao_objetivo(xk)))\n",
        "    \n",
        " "
      ],
      "metadata": {
        "id": "CV23k9XbKgMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "if __name__ == '__main__':\n",
        "    eps = 1e-5\n",
        "    x0 = np.array([-5,-5,-5,-5])#([-1,-1,-1,-1])#([0.1,0.1,0.1,0.1])#([0,0,0,0])###([-3,-3,-3,-3])#([0.0, 0.0])#\n",
        "          \n",
        "         # Método de iteración de Newton\n",
        "    #W = newton(x0,eps)\n",
        "    step = 0\n",
        "    xk = x0\n",
        "    gk = gradiente(xk)\n",
        "    hess = hessiana(xk)\n",
        "    sigma = np.linalg.norm(gk)\n",
        "    sk = -1 * np.dot(np.linalg.inv(hess), gk)\n",
        "    w = np.zeros ((4, 2000)) # Guarde la iteración y establezca la variable xk\n",
        " \n",
        "    while sigma > eps and step < 20:\n",
        "                 # método newton en alfa = 1\n",
        "        w[:, step] = np.transpose(xk)\n",
        " \n",
        "        step += 1\n",
        "        xk = xk + sk\n",
        "        gk = gradiente(xk)\n",
        "        hess = hessiana(xk)\n",
        "        sigma = np.linalg.norm(gk)\n",
        "        sk = -1 * np.dot(np.linalg.inv(hess), gk)\n",
        "        print('--A {}-ésima iter, resultado é {}, função objetivo {:.4f}'.format(step, np.array(xk), funcao_objetivo(xk)))\n",
        "         # Método de amortiguación de Newton\n",
        "    #W = Damped_newton(x0, eps)\n",
        " \n",
        "         # Algoritmo de gradiente conjugado\n",
        "    #W = conjugate_gradient(x0, eps)\n",
        " \n",
        " \n"
      ],
      "metadata": {
        "id": "XNu1lXvPKmQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jOt-Or42PHOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}